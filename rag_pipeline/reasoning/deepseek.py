import os
from openai import OpenAI
from typing import Iterator, Tuple
from .utils import build_retrieval_prompt



def DeepSeek(query: str,
             top_text_parents: str,
             top_media_parents: str,
             model: str = "deepseek-reasoner", # R1, "deepseek-chat" v3,
             max_tokens: int = 64 * 1024,
             temperature: float = 0.7):

    # build llm input
    prompt_input = build_retrieval_prompt(query, top_text_parents, top_media_parents)
    
    # llm reasoning
    print("------------llm reasoning--------------")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    if not deepseek_key:
        raise RuntimeError("è¯·å…ˆç¡®ä¿ DEEPSEEK_API_KEY å·²æ­£ç¡®è®¾ç½®å¹¶æ¿€æ´»äº† mmrag ç¯å¢ƒ")

    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant"},
            {"role": "user", "content": prompt_input},
        ],
        max_tokens  = max_tokens,     
        temperature = temperature,
        stream=False
    )
    
    return response


def DeepSeek_Stream(query: str,
                    top_text_parents: str,
                    top_media_parents: str,
                    model: str = "deepseek-reasoner", # R1, "deepseek-chat" v3,    
                    max_tokens: int = 64 * 1024,
                    temperature: float = 0.7) -> Tuple[Iterator[str], "callable"]:

    """
    è¿”å› (token_iterator, done)ï¼š
          token_iterator â€” é€ token å­—ç¬¦ä¸²ï¼Œå¯ç›´æ¥ for å¾ªç¯ / yield ç»™å‰ç«¯
          done()         â€” è°ƒç”¨åå¾—åˆ°å®Œæ•´å›å¤æ–‡æœ¬ï¼ˆå·²è‡ªåŠ¨ç´¯è®¡ï¼‰
    """
  
    # build llm input
    prompt_input = build_retrieval_prompt(query, top_text_parents, top_media_parents)

    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    if not deepseek_key:
        raise RuntimeError("DEEPSEEK_API_KEY æœªè®¾ç½®")

    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")

    # -------------------------------------------
    stream_resp = client.chat.completions.create(
        model       = model,
        messages    = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user",   "content": prompt_input},
        ],
        max_tokens  = max_tokens,
        temperature = temperature,
        stream      = True,
    )

    # ------------------
    reasoning_parts, answer_parts = [], []
    # def _iter_tokens():
    #     for chunk in stream_resp:
    #         delta = chunk.choices[0].delta
    #         if getattr(delta, "reasoning_content", None):
    #             tok = delta.reasoning_content
    #             reasoning_parts.append(tok)
    #             yield tok                           # æ¨ç† token
    #         elif getattr(delta, "content", None):
    #             tok = delta.content
    #             answer_parts.append(tok)
    #             yield tok     
                
    
    def _iter_tokens() -> Iterator[str]:
        thinking = True          # True â†’ æ­£åœ¨è¾“å‡º reasoning_content
        for chunk in stream_resp:
            delta = chunk.choices[0].delta

            # 1) æ€ç»´é“¾é˜¶æ®µ
            if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                token = delta.reasoning_content
                reasoning_parts.append(token)        # éœ€è¦æ—¶å¯åˆ†å¼€ç´¯ç§¯
                yield token                          # or yield f"[THINK]{token}"
                continue

            # 2) æ­£æ–‡é˜¶æ®µ
            if hasattr(delta, "content") and delta.content:
                if thinking:                         # æ€ç»´é“¾åˆšç»“æŸï¼Œæ’å…¥åˆ†éš”
                    thinking = False
                    yield "\n--- ğŸ¤” æ€è€ƒå®Œæ¯•ï¼Œä»¥ä¸‹ä¸ºå›ç­” ---\n"
                token = delta.content
                answer_parts.append(token)
                yield token

    
    def _done() -> Tuple[str, str]:
        return "".join(reasoning_parts), "".join(answer_parts)

    
    return _iter_tokens(), _done




# token_iter, done = deepseek_r1_stream("Explain Fourier transform.")

# for tok in token_iter:            # å®æ—¶æ‰“å° / æ¨é€
#     print(tok, end="", flush=True)

# print("\n\n--- å®Œæ•´ç»“æœ ---")
# print(done())

